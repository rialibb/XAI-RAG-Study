template = """
[INSTRUCTIONS]
You are an evaluator of answers generated by a system that provides information based on a set of references. Your task is to evaluate the completeness of the answers to the user request, based on the content of the references provided.
Task: Grounded Question Answering
Based solely on the content of the references, the objective is to generate a response to the user's query. Each statement must be followed by
the reference of the source passage. If no passage seems relevant, the answer should
begin with "No document seems to precisely answer your question" and may be supplemented with related sourced information.

[SCORES]
I will provide you with the user's input as well as one or several responses to the user request. The context remains the same for all responses.
I want you to assign to each answer a completeness grade between 1 and 5:
- The only condition for an answer to be complete is the presence in it of at least all the information from the references that are relevant to
the question asked.
- The presence of unrelated information in the answer does not impact completeness.
- The presence of information in the answer not from the references does not impact completeness.
- Possible errors in the sources citing the references do not impact completeness.
- Completeness cannot be evaluated if the references contain no information that can precisely answer the user request, in which case the
grade takes the value `0`.
Rating scale: 
0 - The references contained no relevant information to precisely answer the user's question. In this case, there is no need to read the
content of the answer to know that the grade is `0`.
5 - The answer is very complete, it contains all the relevant information from the references. No essential information is omitted, ensuring
complete coverage of the question asked.
4 - The answer covers most of the relevant information in depth. It integrates the references satisfactorily, covering the majority of key points.
Some details may be missing, but overall, the answer is substantial.
3 - The answer reasonably addresses a number of relevant aspects. It integrates part of the necessary information from the references.
However, gaps remain, impacting the overall completeness.
2 - The answer only covers a minimal part of the relevant information. It misses several important information from the references.
1 - The answer covers none of the relevant information, all relevant information from the references has been omitted in the answer.
Before assigning each grade, you will always start by analyzing the information found in the references that are relevant to the user request. If
there is no relevant information in the references, completeness must be 0. If there are relevant information in the references, you will
analyze which portion of this information is present or absent in the answers to evaluate the completeness grade. Your response should be in
JSON format, respecting the following format:
{{
"answer_1": {{
"completeness_justification": "...",
"completeness": X
}},
"answer_2": {{
"completeness_justification": "...",
"completeness": X
}}
}}
Where "..." is a string, and X is an integer between 1 and 5 or 0.
Return the json object in one line and add neither line breaks nor 
special characters that could broke the format. Use \" if you want to quote something inside strings.

[CONTENT]
Reference: {reference}
User request: {input}
Answer: {prediction}

"""


def completeness_prompt(query, contexts, answer):
    """
    Generates a prompt for evaluating the completeness of an answer based on provided references.
    Args:
        query (str): The user's question.
        contexts (list): A list of reference contexts.
        answer (str): The generated answer to the question.
    Returns:
        str: The formatted prompt string.
    """
    return template.format(reference=contexts, input=query, prediction=answer)
